import type * as ai from '@vscode/ai'
import * as vscode from 'vscode'
import { ConfigService } from '../services/ConfigService'
import { Logger } from '../core/Logger'
import { DEFAULTS } from '../core/Constants'

type AgentOutput = {
	type: 'suggestion'
	language: 'vi'
	summary: string
	code_fix: string
	reasoning: string
	improved_code: string
}

function buildPrompt(input: string) {
	const tpl = `B·∫°n l√† tr·ª£ l√Ω ƒë√°nh gi√° v√† c·∫£i thi·ªán m√£. Tr·∫£ l·ªùi CH·ªà b·∫±ng JSON v·ªõi c√°c tr∆∞·ªùng: type, language, summary, code_fix, reasoning, improved_code. Lu√¥n d√πng ti·∫øng Vi·ªát cho summary, code_fix, reasoning. Kh√¥ng th√™m vƒÉn b·∫£n ngo√†i JSON.
M√£ ngu·ªìn:
\n\n${input}\n\n`.
		concat('Y√™u c·∫ßu: Ph√¢n t√≠ch v·∫•n ƒë·ªÅ, ƒë·ªÅ xu·∫•t ch·ªânh s·ª≠a, gi·∫£i th√≠ch ng·∫Øn g·ªçn, v√† cung c·∫•p phi√™n b·∫£n m√£ ƒë√£ c·∫£i thi·ªán.')
	return tpl
}

async function callOllama(prompt: string, configService: ConfigService, logger: Logger): Promise<string> {
	const apiUrl = configService.getApiUrl()
	const model = configService.getModel()

	logger.info(`Calling Ollama API: ${apiUrl} with model: ${model}`)

	// Create abort controller for timeout
	const controller = new AbortController()
	const timeout = setTimeout(() => {
		logger.warn(`Request timeout after ${DEFAULTS.REQUEST_TIMEOUT_MS}ms`)
		controller.abort()
	}, DEFAULTS.REQUEST_TIMEOUT_MS)

	try {
		const res = await fetch(apiUrl, {
			method: 'POST',
			headers: { 'Content-Type': 'application/json' },
			body: JSON.stringify({ model, prompt, stream: false }),
			signal: controller.signal
		})

		clearTimeout(timeout)

		if (!res.ok) {
			const errorText = await res.text().catch(() => 'Unknown error')
			logger.error(`HTTP ${res.status}: ${errorText}`)
			throw new Error(`HTTP ${res.status}: ${errorText}`)
		}

		const data = await res.json() as { response?: string }
		logger.info('Received response from Ollama')
		return data.response ?? ''
	} catch (err: any) {
		clearTimeout(timeout)

		if (err.name === 'AbortError') {
			const msg = `Request timed out after ${DEFAULTS.REQUEST_TIMEOUT_MS / 1000}s`
			logger.error(msg)
			throw new Error(msg)
		}

		logger.error('Ollama request failed', err)
		throw err
	}
}

function safeParse(output: string, original: string, logger: Logger): AgentOutput {
	const extracted = extractJson(output)
	try {
		const obj = extracted ? JSON.parse(extracted) : JSON.parse(output)
		if (
			obj &&
			obj.type === 'suggestion' &&
			obj.language === 'vi' &&
			typeof obj.summary === 'string' &&
			typeof obj.code_fix === 'string' &&
			typeof obj.reasoning === 'string' &&
			typeof obj.improved_code === 'string'
		) {
			logger.info('Successfully parsed agent output')
			return obj as AgentOutput
		}
	} catch (e) {
		logger.warn('Failed to parse JSON response, using fallback')
	}

	const fallback: AgentOutput = {
		type: 'suggestion',
		language: 'vi',
		summary: output || 'Kh√¥ng th·ªÉ ph√¢n t√≠ch JSON t·ª´ ph·∫£n h·ªìi.',
		code_fix: 'Xem ƒë·ªÅ xu·∫•t ·ªü ph·∫ßn t√≥m t·∫Øt. H√£y ƒë·∫£m b·∫£o ƒë·ªãnh d·∫°ng JSON chu·∫©n.',
		reasoning: 'M√¥ h√¨nh tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng kh√°c y√™u c·∫ßu. ƒê√£ cung c·∫•p t√≥m t·∫Øt d·ª±a tr√™n ph·∫£n h·ªìi th√¥.',
		improved_code: original
	}
	return fallback
}

export async function analyzeWithDeepseek(input: string): Promise<AgentOutput> {
	const logger = Logger.getInstance()
	const configService = new ConfigService()
	const prompt = buildPrompt(input)

	try {
		logger.info('Starting code analysis')
		const responseText = await callOllama(prompt, configService, logger)
		const result = safeParse(responseText, input, logger)
		logger.info('Analysis completed successfully')
		return result
	} catch (e: any) {
		const msg = typeof e?.message === 'string' ? e.message : 'Kh√¥ng x√°c ƒë·ªãnh'
		logger.error('Analysis failed', e)

		// Improved error message with troubleshooting steps
		return {
			type: 'suggestion',
			language: 'vi',
			summary: `‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi Ollama: ${msg}`,
			code_fix: `
üìã C√°c b∆∞·ªõc kh·∫Øc ph·ª•c:

1Ô∏è‚É£ Ki·ªÉm tra Ollama ƒëang ch·∫°y:
   \`ollama ps\`

2Ô∏è‚É£ N·∫øu ch∆∞a ch·∫°y, kh·ªüi ƒë·ªông service:
   \`ollama serve\`

3Ô∏è‚É£ Ki·ªÉm tra model ƒë√£ c√†i ƒë·∫∑t:
   \`ollama list\`

4Ô∏è‚É£ N·∫øu thi·∫øu deepseek-v3, c√†i ƒë·∫∑t:
   \`ollama pull deepseek-v3\`

5Ô∏è‚É£ Ki·ªÉm tra API URL trong Settings:
   M·∫∑c ƒë·ªãnh: http://localhost:11434/api/generate

6Ô∏è‚É£ Ki·ªÉm tra firewall/antivirus kh√¥ng ch·∫∑n port 11434
`,
			reasoning: `Chi ti·∫øt l·ªói: ${msg}\n\nTh·ªùi gian timeout: ${DEFAULTS.REQUEST_TIMEOUT_MS / 1000}s`,
			improved_code: input
		}
	}
}

function extractJson(text: string): string | null {
	const fenceIdx = text.indexOf('```json')
	if (fenceIdx !== -1) {
		const rest = text.slice(fenceIdx + 7)
		const endFence = rest.indexOf('```')
		if (endFence !== -1) return rest.slice(0, endFence).trim()
	}
	const start = text.indexOf('{')
	if (start === -1) return null
	let depth = 0
	for (let i = start; i < text.length; i++) {
		const ch = text[i]
		if (ch === '{') depth++
		else if (ch === '}') {
			depth--
			if (depth === 0) return text.slice(start, i + 1)
		}
	}
	return null
}

export async function registerDeepseekAgent(_context: unknown): Promise<void> {
}
